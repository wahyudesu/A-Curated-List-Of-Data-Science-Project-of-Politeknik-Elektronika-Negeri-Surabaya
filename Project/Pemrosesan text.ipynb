{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Project Pemrosesan Text</center></h1>\n",
    "<h2><center>Pemrosesan Data</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo pens.png\" \n",
    "        alt=\"Picture\" \n",
    "        width=\"380\" \n",
    "        height=\"380\" \n",
    "        style=\"display: block; margin: 0 auto\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Wahyu Ikbal Maulana</center></h3>\n",
    "\n",
    "<h3><center>3323600056</center></h3>\n",
    "\n",
    "<h3><center>D3 SDT B</center></h3>\n",
    "\n",
    "<h1><center>Politeknik Elektronika Negeri Surabaya</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from math import log10, sqrt\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "stopwords_factory = StopWordRemoverFactory()\n",
    "stopwords = stopwords_factory.get_stop_words()\n",
    "\n",
    "# Kata kunci\n",
    "query = 'Kuning Hijau merah biru ada empat'\n",
    "\n",
    "# Dokumen\n",
    "D1 = 'Balonku ada dua rupa-rupa warnanya'\n",
    "D2 = 'Hijau kuning kelabu merah muda dan biru'\n",
    "D3 = 'Meletus balon hijau duar hati wahyu sangat kacau'\n",
    "D4 = 'Balonku tinggal satu Kupegang erat-erat'\n",
    "\n",
    "list_of_dokumen = [D1,D2,D3,D4]\n",
    "len_of_dokumen = len(list_of_dokumen)\n",
    "len_of_dokumen_with_query = len([query, D1, D2, D3, D4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of word: ['balon', 'rupa', 'warna', 'hijau', 'kuning', 'kelabu', 'merah', 'muda', 'biru', 'letus', 'duar', 'hati', 'wahyu', 'sangat', 'kacau', 'tinggal', 'satu', 'pegang', 'erat']\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk mendapatkan list dari seluruh kata yang ada pada list dokumen\n",
    "def get_list_of_word(list_of_dokumen, stopwords):\n",
    "    list_of_word = []\n",
    "    for sentence in list_of_dokumen:\n",
    "        for word in stemmer.stem(sentence).split():\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            if word not in stopwords and stemmed_word not in list_of_word:\n",
    "                list_of_word.append(stemmed_word)\n",
    "    return list_of_word\n",
    "\n",
    "list_of_word = get_list_of_word(list_of_dokumen, stopwords)\n",
    "print('List of word:', list_of_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_term_frequency(list_of_word, len_dokumen_with_query):\n",
    "    term_frequency = []\n",
    "    \n",
    "    for i in range(len_dokumen_with_query):\n",
    "        term_frequency.append(\n",
    "            dict(zip(list_of_word,[0 for _ in range(len(list_of_word))])))\n",
    "    return term_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'balon': 0, 'rupa': 0, 'warna': 0, 'hijau': 1, 'kuning': 1, 'kelabu': 0, 'merah': 1, 'muda': 0, 'biru': 1, 'letus': 0, 'duar': 0, 'hati': 0, 'wahyu': 0, 'sangat': 0, 'kacau': 0, 'tinggal': 0, 'satu': 0, 'pegang': 0, 'erat': 0}, {'balon': 1, 'rupa': 1, 'warna': 1, 'hijau': 0, 'kuning': 0, 'kelabu': 0, 'merah': 0, 'muda': 0, 'biru': 0, 'letus': 0, 'duar': 0, 'hati': 0, 'wahyu': 0, 'sangat': 0, 'kacau': 0, 'tinggal': 0, 'satu': 0, 'pegang': 0, 'erat': 0}, {'balon': 0, 'rupa': 0, 'warna': 0, 'hijau': 1, 'kuning': 1, 'kelabu': 1, 'merah': 1, 'muda': 1, 'biru': 1, 'letus': 0, 'duar': 0, 'hati': 0, 'wahyu': 0, 'sangat': 0, 'kacau': 0, 'tinggal': 0, 'satu': 0, 'pegang': 0, 'erat': 0}, {'balon': 1, 'rupa': 0, 'warna': 0, 'hijau': 1, 'kuning': 0, 'kelabu': 0, 'merah': 0, 'muda': 0, 'biru': 0, 'letus': 1, 'duar': 1, 'hati': 1, 'wahyu': 1, 'sangat': 1, 'kacau': 1, 'tinggal': 0, 'satu': 0, 'pegang': 0, 'erat': 0}, {'balon': 1, 'rupa': 0, 'warna': 0, 'hijau': 0, 'kuning': 0, 'kelabu': 0, 'merah': 0, 'muda': 0, 'biru': 0, 'letus': 0, 'duar': 0, 'hati': 0, 'wahyu': 0, 'sangat': 0, 'kacau': 0, 'tinggal': 1, 'satu': 1, 'pegang': 1, 'erat': 1}]\n"
     ]
    }
   ],
   "source": [
    "term_frequency = create_term_frequency(list_of_word, len_of_dokumen_with_query)\n",
    "\n",
    "for index, sentence in enumerate([query, D1, D2, D3, D4]):\n",
    "    for word in stemmer.stem(sentence).split(' '):\n",
    "        if word in term_frequency[index]:\n",
    "            term_frequency[index][word] += 1\n",
    "\n",
    "print(term_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'balon': 3, 'rupa': 1, 'warna': 1, 'hijau': 2, 'kuning': 1, 'kelabu': 1, 'merah': 1, 'muda': 1, 'biru': 1, 'letus': 1, 'duar': 1, 'hati': 1, 'wahyu': 1, 'sangat': 1, 'kacau': 1, 'tinggal': 1, 'satu': 1, 'pegang': 1, 'erat': 1}\n"
     ]
    }
   ],
   "source": [
    "def create_document_frequency(list_of_word):\n",
    "    return dict(zip(list_of_word, [0 for _ in range(len(list_of_word))]))\n",
    "\n",
    "dokumen_frequency = create_document_frequency(list_of_word)\n",
    "\n",
    "for index, sentence in enumerate(term_frequency):\n",
    "    if index > 0:\n",
    "        for key, value in sentence.items():\n",
    "            if value:\n",
    "                dokumen_frequency[key] += 1\n",
    "                \n",
    "print(dokumen_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'balon': 1.3333333333333333, 'rupa': 4.0, 'warna': 4.0, 'hijau': 2.0, 'kuning': 4.0, 'kelabu': 4.0, 'merah': 4.0, 'muda': 4.0, 'biru': 4.0, 'letus': 4.0, 'duar': 4.0, 'hati': 4.0, 'wahyu': 4.0, 'sangat': 4.0, 'kacau': 4.0, 'tinggal': 4.0, 'satu': 4.0, 'pegang': 4.0, 'erat': 4.0}\n",
      "{'balon': 0.125, 'rupa': 0.602, 'warna': 0.602, 'hijau': 0.301, 'kuning': 0.602, 'kelabu': 0.602, 'merah': 0.602, 'muda': 0.602, 'biru': 0.602, 'letus': 0.602, 'duar': 0.602, 'hati': 0.602, 'wahyu': 0.602, 'sangat': 0.602, 'kacau': 0.602, 'tinggal': 0.602, 'satu': 0.602, 'pegang': 0.602, 'erat': 0.602}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mendapatkan d_df. Di mana itu adalah pembagian antara jumlah dokumen dan nilai document frequency\n",
    "def get_d_df(length_of_document, document_frequency):\n",
    "  d_df = {}\n",
    "\n",
    "  for key, value in document_frequency.items():\n",
    "    d_df[key] = length_of_document / value\n",
    "\n",
    "  return d_df\n",
    "\n",
    "# Mendapatkan niali idf dari d_df\n",
    "def get_idf(d_df):\n",
    "  idf = {}\n",
    "\n",
    "  for key, value in d_df.items():\n",
    "    idf[key] = round(log10(value), 3)\n",
    "\n",
    "  return idf\n",
    "\n",
    "d_df = get_d_df(len_of_dokumen, dokumen_frequency)\n",
    "print(d_df)\n",
    "\n",
    "idf = get_idf(d_df)\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'balon': 0.0, 'rupa': 0.0, 'warna': 0.0, 'hijau': 0.301, 'kuning': 0.602, 'kelabu': 0.0, 'merah': 0.602, 'muda': 0.0, 'biru': 0.602, 'letus': 0.0, 'duar': 0.0, 'hati': 0.0, 'wahyu': 0.0, 'sangat': 0.0, 'kacau': 0.0, 'tinggal': 0.0, 'satu': 0.0, 'pegang': 0.0, 'erat': 0.0}, {'balon': 0.125, 'rupa': 0.602, 'warna': 0.602, 'hijau': 0.0, 'kuning': 0.0, 'kelabu': 0.0, 'merah': 0.0, 'muda': 0.0, 'biru': 0.0, 'letus': 0.0, 'duar': 0.0, 'hati': 0.0, 'wahyu': 0.0, 'sangat': 0.0, 'kacau': 0.0, 'tinggal': 0.0, 'satu': 0.0, 'pegang': 0.0, 'erat': 0.0}, {'balon': 0.0, 'rupa': 0.0, 'warna': 0.0, 'hijau': 0.301, 'kuning': 0.602, 'kelabu': 0.602, 'merah': 0.602, 'muda': 0.602, 'biru': 0.602, 'letus': 0.0, 'duar': 0.0, 'hati': 0.0, 'wahyu': 0.0, 'sangat': 0.0, 'kacau': 0.0, 'tinggal': 0.0, 'satu': 0.0, 'pegang': 0.0, 'erat': 0.0}, {'balon': 0.125, 'rupa': 0.0, 'warna': 0.0, 'hijau': 0.301, 'kuning': 0.0, 'kelabu': 0.0, 'merah': 0.0, 'muda': 0.0, 'biru': 0.0, 'letus': 0.602, 'duar': 0.602, 'hati': 0.602, 'wahyu': 0.602, 'sangat': 0.602, 'kacau': 0.602, 'tinggal': 0.0, 'satu': 0.0, 'pegang': 0.0, 'erat': 0.0}, {'balon': 0.125, 'rupa': 0.0, 'warna': 0.0, 'hijau': 0.0, 'kuning': 0.0, 'kelabu': 0.0, 'merah': 0.0, 'muda': 0.0, 'biru': 0.0, 'letus': 0.0, 'duar': 0.0, 'hati': 0.0, 'wahyu': 0.0, 'sangat': 0.0, 'kacau': 0.0, 'tinggal': 0.602, 'satu': 0.602, 'pegang': 0.602, 'erat': 0.602}]\n"
     ]
    }
   ],
   "source": [
    "def get_w_q_t(term_frequency, idf):\n",
    "  w_q_t = []\n",
    "\n",
    "  for index, document in enumerate(term_frequency):\n",
    "    w_q_t.append({})\n",
    "\n",
    "    for key, value in document.items():\n",
    "      w_q_t[index][key] = value * idf[key]\n",
    "\n",
    "  return w_q_t \n",
    "\n",
    "w_q_t = get_w_q_t(term_frequency, idf)\n",
    "print(w_q_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bobot_query(w_q_t, query):\n",
    "    bobot_query = []\n",
    "\n",
    "    # Iterate over each document in w_q_t, starting from the second document (index 1)\n",
    "    for index, dokumen in enumerate(w_q_t):\n",
    "        if index > 0:\n",
    "            bobot_query.append({})\n",
    "            # Stem the query and split into words\n",
    "            stemmed_query_words = stemmer.stem(query).split(\" \")\n",
    "            for word in stemmed_query_words:\n",
    "                if word in dokumen:  # Check if the word exists in the document\n",
    "                    bobot_query[index-1][word] = dokumen[word]\n",
    "                else:\n",
    "                    bobot_query[index-1][word] = 0  # If word not found, set to 0\n",
    "      \n",
    "    return bobot_query\n",
    "\n",
    "\n",
    "# Mendapatkan q_d di mana q_d adalah hasil pangkat dari nilai-nilai w_q_t \n",
    "def get_q_d(w_q_t):\n",
    "  q_d = []\n",
    "\n",
    "  for index, document in enumerate(w_q_t):\n",
    "    q_d.append({})\n",
    "    total = 0\n",
    "\n",
    "    for key, value in document.items():\n",
    "      q_d[index][key] = round(value ** 2, 3)\n",
    "      total += q_d[index][key]\n",
    "    q_d[index][\"total\"] = round(sqrt(total), 3)\n",
    "\n",
    "  # q_d.pop()\n",
    "  return q_d\n",
    "\n",
    "def get_sum_of_tf_q_d(term_frequency, bobot_kata_kunci_q_d):\n",
    "  sum_of_tf_q_d = []\n",
    "\n",
    "  for index, document in enumerate(term_frequency):\n",
    "    if index > 0:\n",
    "      sum_of_tf_q_d.append({})\n",
    "\n",
    "      for key, value in document.items():\n",
    "        if key in bobot_kata_kunci_q_d:\n",
    "          sum_of_tf_q_d[index-1][key] = value * bobot_kata_kunci_q_d[key]\n",
    "          \n",
    "  return sum_of_tf_q_d\n",
    "\n",
    "def get_bobot_kata_kunci_q_d(q_d, kata_kunci):\n",
    "  bobot_kata_kunci_q_d = {}\n",
    "\n",
    "  for word in stemmer.stem(kata_kunci).split(\" \"):\n",
    "    bobot_kata_kunci_q_d[word] = q_d[0][word]\n",
    "\n",
    "  return bobot_kata_kunci_q_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'kuning': 0.0, 'hijau': 0.0, 'merah': 0.0, 'biru': 0.0, 'ada': 0, 'empat': 0}, {'kuning': 0.602, 'hijau': 0.301, 'merah': 0.602, 'biru': 0.602, 'ada': 0, 'empat': 0}, {'kuning': 0.0, 'hijau': 0.301, 'merah': 0.0, 'biru': 0.0, 'ada': 0, 'empat': 0}, {'kuning': 0.0, 'hijau': 0.0, 'merah': 0.0, 'biru': 0.0, 'ada': 0, 'empat': 0}]\n"
     ]
    }
   ],
   "source": [
    "bobot_query = get_bobot_query(w_q_t, query)\n",
    "print(bobot_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'balon': 0.0, 'rupa': 0.0, 'warna': 0.0, 'hijau': 0.091, 'kuning': 0.362, 'kelabu': 0.0, 'merah': 0.362, 'muda': 0.0, 'biru': 0.362, 'letus': 0.0, 'duar': 0.0, 'hati': 0.0, 'wahyu': 0.0, 'sangat': 0.0, 'kacau': 0.0, 'tinggal': 0.0, 'satu': 0.0, 'pegang': 0.0, 'erat': 0.0, 'total': 1.085}, {'balon': 0.016, 'rupa': 0.362, 'warna': 0.362, 'hijau': 0.0, 'kuning': 0.0, 'kelabu': 0.0, 'merah': 0.0, 'muda': 0.0, 'biru': 0.0, 'letus': 0.0, 'duar': 0.0, 'hati': 0.0, 'wahyu': 0.0, 'sangat': 0.0, 'kacau': 0.0, 'tinggal': 0.0, 'satu': 0.0, 'pegang': 0.0, 'erat': 0.0, 'total': 0.86}, {'balon': 0.0, 'rupa': 0.0, 'warna': 0.0, 'hijau': 0.091, 'kuning': 0.362, 'kelabu': 0.362, 'merah': 0.362, 'muda': 0.362, 'biru': 0.362, 'letus': 0.0, 'duar': 0.0, 'hati': 0.0, 'wahyu': 0.0, 'sangat': 0.0, 'kacau': 0.0, 'tinggal': 0.0, 'satu': 0.0, 'pegang': 0.0, 'erat': 0.0, 'total': 1.379}, {'balon': 0.016, 'rupa': 0.0, 'warna': 0.0, 'hijau': 0.091, 'kuning': 0.0, 'kelabu': 0.0, 'merah': 0.0, 'muda': 0.0, 'biru': 0.0, 'letus': 0.362, 'duar': 0.362, 'hati': 0.362, 'wahyu': 0.362, 'sangat': 0.362, 'kacau': 0.362, 'tinggal': 0.0, 'satu': 0.0, 'pegang': 0.0, 'erat': 0.0, 'total': 1.51}, {'balon': 0.016, 'rupa': 0.0, 'warna': 0.0, 'hijau': 0.0, 'kuning': 0.0, 'kelabu': 0.0, 'merah': 0.0, 'muda': 0.0, 'biru': 0.0, 'letus': 0.0, 'duar': 0.0, 'hati': 0.0, 'wahyu': 0.0, 'sangat': 0.0, 'kacau': 0.0, 'tinggal': 0.362, 'satu': 0.362, 'pegang': 0.362, 'erat': 0.362, 'total': 1.21}]\n"
     ]
    }
   ],
   "source": [
    "q_d = get_q_d(w_q_t)\n",
    "print(q_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bobot_kk_and_document(q_d):\n",
    "  bobot_kk_and_document = {}\n",
    "\n",
    "  for index, dokumen in enumerate(q_d):\n",
    "    for key, value in dokumen.items():\n",
    "      if key == \"total\":\n",
    "        if index == 0:\n",
    "          bobot_kk_and_document[\"bobot_kata_kunci\"] = value\n",
    "        else:\n",
    "          bobot_kk_and_document[f\"bobot_dokumen_{index}\"] = value\n",
    "\n",
    "  return bobot_kk_and_document\n",
    "\n",
    "def get_bobot_sum_of_tf_q_d(sum_of_tf_q_d):\n",
    "  bobot_sum_of_tf_q_d = {}\n",
    "\n",
    "  for index, document in enumerate(sum_of_tf_q_d):\n",
    "    total = 0\n",
    "    for _, value in document.items():\n",
    "      total += value\n",
    "    bobot_sum_of_tf_q_d[f\"bobot_sum_of_tf_q_d_{index+1}\"] = total\n",
    "\n",
    "  return bobot_sum_of_tf_q_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bobot dari kk dan dokumen berdasarkan q/d: \n",
      "\n",
      "0.249\n",
      "0.539\n",
      "0.509\n",
      "0.643\n",
      "\n",
      "Total bobot dokumen dari Tf * (Wq ^ 2): \n",
      "\n",
      "0.031\n",
      "0.031\n",
      "0.093\n",
      "\n",
      "Hasil akhir dokumen: \n",
      "\n",
      "0.381\n",
      "0.36\n",
      "0.788\n",
      "\n",
      "Urutan Dokumen: \n",
      "\n",
      "{'nama': 'Dokumen 3', 'nilai': 0.788}\n",
      "{'nama': 'Dokumen 1', 'nilai': 0.381}\n",
      "{'nama': 'Dokumen 2', 'nilai': 0.36}\n"
     ]
    }
   ],
   "source": [
    "# Mendapatkan list dari seluruh kata-kata yang ada pada list dokumen\n",
    "# di mana kata-kata tersebut bukan stopwords dan sudah di-stem\n",
    "def get_list_of_word(list_of_document, stopwords):\n",
    "  list_of_word = []\n",
    "\n",
    "  for sentence in list_of_document:\n",
    "    for word in stemmer.stem(sentence).split(\" \"):\n",
    "      stemmed_word = stemmer.stem(word)\n",
    "      if word not in stopwords and stemmed_word not in list_of_word:\n",
    "        list_of_word.append(stemmed_word) \n",
    "\n",
    "  return list_of_word\n",
    "\n",
    "\n",
    "# membuat sebuah list yang berisi kumpulan \n",
    "# word yang nilai awalnya adalah 0 \n",
    "def create_term_frequency(list_of_word, length_of_document_with_kk):\n",
    "  term_frequency = []\n",
    "\n",
    "  for _ in range(length_of_document_with_kk):\n",
    "    term_frequency.append(\n",
    "      dict(zip(list_of_word, [0 for _ in range(len(list_of_word))]))\n",
    "    ) \n",
    "\n",
    "  return term_frequency\n",
    "\n",
    "# Membuat dokumen frequency yaitu sebuah dictionary yang berisi kata-kata untuk term-frequency dengan nilai awal 0 \n",
    "def create_document_frequency(list_of_word):\n",
    "  return dict(zip(list_of_word, [0 for _ in range(len(list_of_word))]))\n",
    "\n",
    "# Mendapatkan d_df. Di mana itu adalah pembagian antara jumlah dokumen dan nilai document frequency\n",
    "def get_d_df(length_of_document, document_frequency):\n",
    "  d_df = {}\n",
    "\n",
    "  for key, value in document_frequency.items():\n",
    "    d_df[key] = length_of_document / value\n",
    "\n",
    "  return d_df\n",
    "\n",
    "# Mendapatkan niali idf dari d_df\n",
    "def get_idf(d_df):\n",
    "  idf = {}\n",
    "\n",
    "  for key, value in d_df.items():\n",
    "    idf[key] = round(log10(value), 3)\n",
    "\n",
    "  return idf\n",
    "\n",
    "#  Mendapatkan W_q_t. Di mana itu merupakann perkalian antara value dengan idf index ke key\n",
    "def get_w_q_t(term_frequency, idf):\n",
    "  w_q_t = []\n",
    "\n",
    "  for index, document in enumerate(term_frequency):\n",
    "    w_q_t.append({})\n",
    "\n",
    "    for key, value in document.items():\n",
    "      w_q_t[index][key] = value * idf[key]\n",
    "\n",
    "  return w_q_t \n",
    "\n",
    "\n",
    "# mendapatkan bobot kata kunci\n",
    "def get_bobot_kata_kunci(w_q_t, kata_kunci):\n",
    "  bobot_kata_kunci = []\n",
    "\n",
    "  for index, document in enumerate(w_q_t):\n",
    "    if index > 0:\n",
    "      bobot_kata_kunci.append({})\n",
    "      for word in stemmer.stem(kata_kunci).split(\" \"):\n",
    "        bobot_kata_kunci[index-1][word] = document[word]\n",
    "      \n",
    "  return bobot_kata_kunci\n",
    "\n",
    "# Mendapatkan q_d di mana q_d adalah hasil pangkat dari nilai-nilai w_q_t \n",
    "def get_q_d(w_q_t):\n",
    "  q_d = []\n",
    "\n",
    "  for index, document in enumerate(w_q_t):\n",
    "    q_d.append({})\n",
    "    total = 0\n",
    "\n",
    "    for key, value in document.items():\n",
    "      q_d[index][key] = round(value ** 2, 3)\n",
    "      total += q_d[index][key]\n",
    "    q_d[index][\"total\"] = round(sqrt(total), 3)\n",
    "\n",
    "  # q_d.pop()\n",
    "  return q_d\n",
    "\n",
    "\n",
    "def get_bobot_kata_kunci_q_d(q_d, kata_kunci):\n",
    "  bobot_kata_kunci_q_d = {}\n",
    "\n",
    "  for word in stemmer.stem(kata_kunci).split(\" \"):\n",
    "    bobot_kata_kunci_q_d[word] = q_d[0][word]\n",
    "\n",
    "  return bobot_kata_kunci_q_d\n",
    "\n",
    " \n",
    "def get_bobot_kk_and_document(q_d):\n",
    "  bobot_kk_and_document = {}\n",
    "\n",
    "  for index, dokumen in enumerate(q_d):\n",
    "    for key, value in dokumen.items():\n",
    "      if key == \"total\":\n",
    "        if index == 0:\n",
    "          bobot_kk_and_document[\"bobot_kata_kunci\"] = value\n",
    "        else:\n",
    "          bobot_kk_and_document[f\"bobot_dokumen_{index}\"] = value\n",
    "\n",
    "  return bobot_kk_and_document\n",
    "\n",
    "def get_sum_of_tf_q_d(term_frequency, bobot_kata_kunci_q_d):\n",
    "  sum_of_tf_q_d = []\n",
    "\n",
    "  for index, document in enumerate(term_frequency):\n",
    "    if index > 0:\n",
    "      sum_of_tf_q_d.append({})\n",
    "\n",
    "      for key, value in document.items():\n",
    "        if key in bobot_kata_kunci_q_d:\n",
    "          sum_of_tf_q_d[index-1][key] = value * bobot_kata_kunci_q_d[key]\n",
    "\n",
    "  return sum_of_tf_q_d\n",
    "\n",
    "def get_bobot_sum_of_tf_q_d(sum_of_tf_q_d):\n",
    "  bobot_sum_of_tf_q_d = {}\n",
    "\n",
    "  for index, document in enumerate(sum_of_tf_q_d):\n",
    "    total = 0\n",
    "    for _, value in document.items():\n",
    "      total += value\n",
    "    bobot_sum_of_tf_q_d[f\"bobot_sum_of_tf_q_d_{index+1}\"] = total\n",
    "\n",
    "  return bobot_sum_of_tf_q_d\n",
    "\n",
    "\n",
    "def get_bobot_document_result(bobot_sum_of_tf_q_d, bobot_kata_kunci, bobot_document): \n",
    "  return round(sqrt(bobot_sum_of_tf_q_d) / (bobot_kata_kunci / bobot_document), 3)\n",
    "\n",
    "# Kata Kunci\n",
    "kata_kunci = \"pengetahuan logistik\"\n",
    "\n",
    "# Stopwords\n",
    "stopwords = stopwords_factory.get_stop_words()\n",
    "\n",
    "# Document\n",
    "document_1 = \"manajemen transaksi logistik\"\n",
    "document_2 = \"pengetahuan antara individu\"\n",
    "document_3 = \"dalam manajemen pengetahuan terdapat transfer pengetahuan logistik\"\n",
    "\n",
    "# List yang berisi kumpulan document dan panjang dari document\n",
    "list_of_document = [document_1, document_2, document_3]\n",
    "length_of_document = len(list_of_document)\n",
    "length_of_document_with_kk = len(\n",
    "  [kata_kunci, document_1, document_2, document_3]\n",
    ")\n",
    "\n",
    "# Kata Kunci\n",
    "kata_kunci = \"pengetahuan logistik\"\n",
    "\n",
    "# Stopwords\n",
    "stopwords = stopwords_factory.get_stop_words()\n",
    "\n",
    "# Document\n",
    "document_1 = \"manajemen transaksi logistik\"\n",
    "document_2 = \"pengetahuan antara individu\"\n",
    "document_3 = \"dalam manajemen pengetahuan terdapat transfer pengetahuan logistik\"\n",
    "\n",
    "# List yang berisi kumpulan document dan panjang dari document\n",
    "list_of_document = [document_1, document_2, document_3]\n",
    "length_of_document = len(list_of_document)\n",
    "length_of_document_with_kk = len(\n",
    "  [kata_kunci, document_1, document_2, document_3]\n",
    ")\n",
    "\n",
    "# Berisi kata-kata yang berasal dari list document\n",
    "list_of_word = get_list_of_word(list_of_document, stopwords)\n",
    "\n",
    "term_frequency = create_term_frequency(list_of_word, length_of_document_with_kk)\n",
    "\n",
    "# Menambahkan nilai dari term frequency sesuai dengan kemunculan di tiap document\n",
    "for index, sentence in enumerate([kata_kunci, document_1, document_2, document_3]):\n",
    "  for word in stemmer.stem(sentence).split(\" \"):\n",
    "    if word in term_frequency[index]:\n",
    "      term_frequency[index][word] += 1 \n",
    "\n",
    "document_frequency = create_document_frequency(list_of_word)\n",
    "\n",
    "# Menambahkan nilai untuk document frequency dengan cara menambahkan sesuai kemunculan kata-kata di tiap document\n",
    "for index, sentence in enumerate(term_frequency):\n",
    "  if index > 0:\n",
    "    for key, value in sentence.items():\n",
    "      if value:\n",
    "        document_frequency[key] += 1\n",
    "\n",
    "d_df = get_d_df(length_of_document, document_frequency)\n",
    "\n",
    "idf = get_idf(d_df)\n",
    "\n",
    "w_q_t = get_w_q_t(term_frequency, idf)\n",
    "\n",
    "bobot_kata_kunci = get_bobot_kata_kunci(w_q_t, kata_kunci)\n",
    "\n",
    "q_d = get_q_d(w_q_t)\n",
    "\n",
    "bobot_kata_kunci_q_d = get_bobot_kata_kunci_q_d(q_d, kata_kunci)\n",
    "\n",
    "bobot_kata_kunci_and_document = get_bobot_kk_and_document(q_d)\n",
    "\n",
    "sum_of_tf_q_d = get_sum_of_tf_q_d(term_frequency, bobot_kata_kunci_q_d)\n",
    "\n",
    "bobot_sum_of_tf_q_d = get_bobot_sum_of_tf_q_d(sum_of_tf_q_d) \n",
    "\n",
    "\n",
    "# Total bobot dari kk dan dokumen berdasarkan q/d.\n",
    "total_bobot_kk = bobot_kata_kunci_and_document[\"bobot_kata_kunci\"]\n",
    "total_bobot_document_1 = bobot_kata_kunci_and_document[\"bobot_dokumen_1\"]\n",
    "total_bobot_document_2 = bobot_kata_kunci_and_document[\"bobot_dokumen_2\"]\n",
    "total_bobot_document_3 = bobot_kata_kunci_and_document[\"bobot_dokumen_3\"]\n",
    "\n",
    "# Total bobot dokumen dari Tf * (Wq ^ 2)\n",
    "bobot_sum_of_tf_q_d_1 = bobot_sum_of_tf_q_d[\"bobot_sum_of_tf_q_d_1\"]\n",
    "bobot_sum_of_tf_q_d_2 = bobot_sum_of_tf_q_d[\"bobot_sum_of_tf_q_d_2\"]\n",
    "bobot_sum_of_tf_q_d_3 = bobot_sum_of_tf_q_d[\"bobot_sum_of_tf_q_d_3\"]\n",
    "\n",
    "print(\"Total bobot dari kk dan dokumen berdasarkan q/d: \\n\")\n",
    "\n",
    "print(total_bobot_kk)\n",
    "print(total_bobot_document_1)\n",
    "print(total_bobot_document_2)\n",
    "print(total_bobot_document_3)\n",
    "\n",
    "print(\"\\nTotal bobot dokumen dari Tf * (Wq ^ 2): \\n\")\n",
    "\n",
    "print(bobot_sum_of_tf_q_d_1)\n",
    "print(bobot_sum_of_tf_q_d_2)\n",
    "print(bobot_sum_of_tf_q_d_3)  \n",
    "\n",
    "document_1_result = get_bobot_document_result(bobot_sum_of_tf_q_d_1, total_bobot_kk, total_bobot_document_1)\n",
    "document_2_result = get_bobot_document_result(bobot_sum_of_tf_q_d_2, total_bobot_kk, total_bobot_document_2)\n",
    "document_3_result = get_bobot_document_result(bobot_sum_of_tf_q_d_3, total_bobot_kk, total_bobot_document_3)\n",
    "\n",
    "print(\"\\nHasil akhir dokumen: \\n\")\n",
    "\n",
    "print(document_1_result)\n",
    "print(document_2_result)\n",
    "print(document_3_result)\n",
    "\n",
    "hasil_akhir = [\n",
    "  {\"nama\": \"Dokumen 1\", \"nilai\": document_1_result},\n",
    "  {\"nama\": \"Dokumen 2\", \"nilai\": document_2_result},\n",
    "  {\"nama\": \"Dokumen 3\", \"nilai\": document_3_result}\n",
    "]\n",
    "\n",
    "hasil_akhir.sort(key=lambda item: item.get(\"nilai\"), reverse=True)\n",
    "\n",
    "print(\"\\nUrutan Dokumen: \\n\")\n",
    "\n",
    "for item in hasil_akhir:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ben\n"
     ]
    }
   ],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "stop_factory = StopWordRemoverFactory()\n",
    "# more_stopword = [‘dengan’, ‘ia’,’bahwa’,’oleh’]\n",
    "data = stop_factory.get_stop_words()\n",
    "# stopword = stop_factory.create_stop_word_remover()\n",
    "if \"hanya\" in data:\n",
    "  print(\"ben\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bobot_sum_of_tf_q_d_1': 0.031, 'bobot_sum_of_tf_q_d_2': 0.031, 'bobot_sum_of_tf_q_d_3': 0.093}\n"
     ]
    }
   ],
   "source": [
    "print(bobot_sum_of_tf_q_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Project Akhir Python OOP</center></h1>\n",
    "<h2><center>Pemrograman 2</center></h2>\n",
    "<h3><center>Dosen Pengampu Tri Hadiah Muliawati</center></h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
